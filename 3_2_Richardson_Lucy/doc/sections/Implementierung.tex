\section{Implementierung}

\subsection{Theorie: Iterative Bildrekonstruktion}

Die \textbf{Richardson-Lucy-Deconvolution (RLD)} ist ein iteratives Verfahren zur Rekonstruktion eines scharfen Bildes aus einem unscharfen Bild, wenn die Art der Unschärfe bekannt ist – diese wird durch die sogenannte \textit{Point Spread Function (PSF)} beschrieben. \\

\noindent
Der Algorithmus beginnt mit einer anfänglichen Schätzung des Originalbildes und verbessert diese in mehreren Iterationen. Dabei wird jeweils überprüft, wie gut die aktuelle Schätzung das unscharfe Bild erklären kann. Die Schätzung wird dann entsprechend angepasst. \\

Die zentrale Gleichung lautet:

\[
\hat{u}_j^{(t+1)} = \hat{u}_j^{(t)} \sum_i \frac{d_i}{c_i} p_{ij}
\]

Dabei bedeuten:

\begin{itemize}
    \item \( \hat{u}_j^{(t)} \): aktuelle Schätzung des scharfen Bildes im \( t \)-ten Iterationsschritt
    \item \( d_i \): gemessene Pixelwerte des unscharfen Bildes
    \item \( p_{ij} \): PSF-Wert, der beschreibt, wie stark das Pixel \( j \) zum unscharfen Pixel \( i \) beiträgt
    \item \( c_i \): Zwischenwert, der angibt, wie gut das aktuelle geschätzte Bild das unscharfe Bild wiedergibt:
    \[
    c_i = \sum_j p_{ij} \hat{u}_j^{(t)}
    \]
\end{itemize}

In jeder Iteration wird die Schätzung \( \hat{u}_j \) so angepasst, dass sie besser zu den beobachteten Daten \( d_i \) passt. Wenn der Algorithmus richtig konvergiert, ergibt sich am Ende ein rekonstruiertes Bild, das unter den gegebenen Bedingungen (Unschärfe und Rauschen) am wahrscheinlichsten das ursprüngliche, scharfe Bild darstellt.

\newpage
\subsection{Umsetzung der Hauptschleife in Python}

Im Code wird die iterative RLD-Methode wie folgt implementiert:

\begin{minted}[linenos]{python}
# Iterative RLD algorithm
for i in range(iterations):
    # Apply the PSF to the current estimate to simulate the blurred version of the estimate.
    estimate_conv = cv.filter2D(estimate, -1, psf, borderType=cv.BORDER_REFLECT)
    
    # Calculate the ratio of the blurred image to the current estimate's blurred version.
    ratio = image_blurred / (estimate_conv + 1e-7)  # Avoid division by zero
    
    # Convolve the ratio with the flipped PSF to compute the correction factor.
    correction = cv.filter2D(ratio, -1, psf_mirror, borderType=cv.BORDER_REFLECT)
    
    # Update the estimate by multiplying it with the correction.
    estimate *= correction
\end{minted}

\subsubsection{Erklärung der Code-Schritte}

\begin{enumerate}
    \item \textbf{Anwenden der PSF}: Zuerst wird die aktuelle Schätzung des Bildes mit der PSF kombiniert, um eine unscharfe Version der Schätzung zu erzeugen (Zeile 4). Dies entspricht dem ersten Schritt der Iteration, bei dem die Schätzung durch die PSF "unscharf gemacht" wird.
    \item \textbf{Berechnung des Verhältnisses}: Es wird nun das Verhältnis zwischen dem unscharfen Bild und der erzeugten unscharfen Version der Schätzung berechnet (Zeile 7). Dieses Verhältnis zeigt, wie stark die Schätzung von der tatsächlichen Unschärfe abweicht.
    \item \textbf{Berechnung des Korrekturfaktors}: Der berechnete Unterschied wird dann mit der gespiegelten PSF kombiniert, um einen Korrekturfaktor zu erhalten (Zeile 10). Dieser Schritt hilft, die Schätzung in die richtige Richtung zu korrigieren.
    \item \textbf{Aktualisierung der Schätzung}: Die Schätzung des Bildes wird schließlich mit diesem Korrekturfaktor multipliziert, um die Schätzung zu verbessern (Zeile 13). Dies ist der eigentliche Iterationsschritt, bei dem die Schätzung Schritt für Schritt näher an die tatsächliche Lösung gebracht wird.
\end{enumerate}

Diese Schritte wiederholen sich, wobei die Schätzung nach jeder Iteration immer genauer wird, was schließlich zu einer besseren Rekonstruktion des Bildes führt.




\newpage
\subsection{Implementierte Filterkernels}

Zur Erzeugung der unscharfen Bilder wurden vier verschiedene Filterkernel implementiert, um unterschiedliche Arten von Unschärfe zu simulieren:

\begin{itemize}
    \item \textbf{Mittelwertfilter}: Ein einfacher 5{\texttimes}5-Kernel, bei dem alle Werte gleich sind. Dies führt zu einer gleichmäßigen Unschärfe über das Bild.
    
    \item \textbf{Gauß-Filter}: Ein 9{\texttimes}9-Kernel mit einer Standardabweichung von 2. Die Werte basieren auf einer Gaußverteilung und wurden mit \texttt{cv.getGaussianKernel()} aus OpenCV generiert.
    
    \item \textbf{Horizontaler Bewegungsfilter}: Ein 1{\texttimes}9-Kernel mit gleichmäßigen Werten in horizontaler Richtung. Dieser simuliert eine Bewegungsunschärfe von links nach rechts.
    
    \item \textbf{Diagonaler Bewegungsfilter}: Ein 9{\texttimes}9-Kernel, der nur entlang der Hauptdiagonale Werte besitzt. Dies simuliert eine diagonale Bewegungsunschärfe.
\end{itemize}
